---
layout: article
aside:
    toc: true
sidebar:
    nav: docs-en
title: 1. Binary Variables
---

# Binary Variables
먼저 $x \in \lbrace 0, 1\rbrace$인 간단한 이진 확률 변수로 시작해보겠습니다.
예를 들어, $x$는 동전 던지기의 결과를 표현하는 확률 변수일 수 있습니다.
$x = 1$은 결과가 '앞면(heads)'이었을 경우를,
$x = 0$은 결과가 '뒷면(tails)'이었을 경우를 나타낼 수 있습니다.
만약 동전이 앞면의 나올 확률과 뒷면이 나올 확률이 동일하지 않다고 가정하면, 앞면($x = 1$)이 나올 확률은 다음과 같이 표현할 수 있습니다.

$$ p(x = 1|\mu) = \mu \tag{2.1}$$

여기서 $0 \leq \mu \leq 1$ 입니다.

$x = 0$인 확률은 다음과 같습니다.

$$ p(x = 0 | \mu) = 1 - \mu$$

따라서, $x$에 대한 확률 분포는 다음과 같이 표현할 수 있습니다.

$$\text{Bern}(x|\mu) = \mu^x(1-\mu)^{1-x} \tag{2.2} $$

이러한 분포를 **베르누이 분포**(bernoulli distribution)라고 합니다. 베르누이 분포는 정규화(normalization)되어 있으며, 평균과 분산은 다음과 같습니다.

$$\begin{align*} \mathbb{E}[x] &= \mu \tag{2.3} \\ \text{var}[x] &= \mu(1-\mu) \tag{2.4} \end{align*}$$

관측된 데이터 집합 $\mathcal{D} = \lbrace x_1, \dots x_N \rbrace$이 주어졌고, 관측값들이 독립적으로 추출되었다고 가정하면
$\mu$의 함수로 가능도 함수를 다음과 같이 구성할 수 있습니다.

$$p(\mathcal{D}|\mu) = \prod_{n=1}^{N}p(x_n|\mu) = \prod_{n=1}^{N}\mu^{x_n}(1 - \mu)^{1-x_n} \tag{2.5}$$

빈도적(frequentist) 관점에서는 가능도 함수를 최대화하거나 로그 가능도(log likelihood) 함수를 최대화하는 $\mu$의 값을 추정할 수 있으며(MLE; maximum likelihood estimation),
베르누이 분포의 경우, 로그 가능도 함수는 다음과 같이 주어집니다.

$$\ln{p}(\mathcal{D}|\mu) = \sum_{n=1}^N \ln{p}(x_n|\mu) = \sum_{n=1}^N \lbrace x_n \ln{\mu} + (1 - x_n)\ln{(1-\mu)} \rbrace \tag{2.6}$$

여기서 주목해야할 점은 로그 가능도 함수가 오직 관측된 데이터의 합 $\sum_n x_n$을 통해서
$x_N$의 개수 N에만 영향을 받는다는 것입니다.
여기서 $\sum_n x_n$은 충분 통계량(sufficient statistic)의 예시 중 하나이며, 이후에 다시 살펴볼 예정입니다.

식 (2.6)을 최대화하는 방법은 바로 극점을 이용하여 구할 수 있습니다. 따라서, 먼저 $\ln{p}(\mathcal{D}|\mu)$를
$\mu$에 대해 미분하고 이를 0과 같다고 놓습니다.

$$\begin{align*} \frac{\mathrm{d}}{\mathrm{d}\mu}\ln p(\mathcal{D}|\mu) &= \sum_{n=1}^{N}\frac{\mathrm{d}}{\mathrm{d}\mu} \left \lbrace  x_n \ln \mu + (1 - x_n) \ln (1-\mu) \right \rbrace \\ &= \sum_{n=1}^N \left \lbrace  \frac{x_n}{\mu} - \frac{1-x^n}{1-\mu} \right \rbrace \\ &= \sum_{n=1}^N \frac{x_n - \mu}{\mu(1-\mu)} = 0 \end{align*}$$

위 계산식의 마지막 항등식에 $\mu(1-\mu)$를 곱하고,
$\mu$에 대해 정리하면 아래 식과 같은 최대 가능도 추정값을 구할 수 있습니다.

$$\mu_{\text{ML}} = \frac{1}{N}\sum_{n=1}^N x_n \tag{2.7}$$

위 식은 **표본 평균**(sample mean)이라고도 불리며, 데이터에서 $x = 1$인 관측값의 수를
$m$이라고 한다면, 위 식을 다음의 형태로 다시 적을 수 있습니다.

$$\mu_{\text{ML}} = \frac{m}{N} \tag{2.8}$$

즉, 다시 동전 던지기 문제로 돌아가서 동전의 앞면이 나올 확률은 데이터 집합에서 앞면이 나온 비율이 됩니다.

만약, 동전을 세 번 던졌는데 세 번 다 앞면이 나왔다고 가정해봅시다. 그러면 $N=m=3$이고,
따라서 $\mu_{\text{ML}} = 1$이 됩니다.
이 경우 최대 가능도에 따라 예측한다면 미래의 관측에서 결과는 모두 앞면이 나올 것으로 예측됩니다.
일반적인 상식에서는 말도 안되는 결과이며, 실제로 이는 최대 가능도와 연관되는 과적합(over-fitting)의 극단적인 예시입니다.
뒤에서는 $\mu$에 대한 사전 분포를 바탕으로 더 합리적인 결과를 도출하는 방법에 대해서 살펴보도록 하겠습니다.

크기가 N인 데이터가 주어졌을 때, $x = 1$인
관측값의 수 $m$에 대한 분포를 생각해볼 수 있습니다.
즉, 동전을 N번 던졌을 때 앞면이 나올 확률 분포를 고려해보도록 하겠습니다. 이를 **이항 분포(binomial distribution)** 라고 합니다. 식 (2.5)으로부터 이항 분포는 $\mu^m(1-\mu)^{N-m}$에 비례한다는 것을 알 수 있고, 정규화(normalization) 계수를 구하기 위해서는 동전 던지기를 N번 했을 때 앞면이 m번 나올 수 있는 모든 경우의 수를 구해야 합니다.
따라서, 이항 분포를 다음과 같이 적을 수 있습니다.

$$\text{Bin}(m|N, \mu) = \binom{N}{m}\mu^m (1-\mu)^{N-m} \tag{2.9}$$

$$\binom{N}{m} \equiv \frac{N!}{(N-m)!m!} \tag{2.10}$$

여기서 (2.10)은 N개의 object에서 m개의 object를 선택하는 경우의 수를 구한 것입니다. 아래의 그림은 $N=10$이고,
$\mu = 0.25$일 때의 이항 분포의 히스토그램을 보여줍니다.

<div align="center"><img src="{{ site.baseurl }}/assets/images/figures/Figure2.1.png" height="300px"></div>
<div align="center">Figure 2.1</div>

이항 분포의 평균과 분산은 다음과 같습니다.

$$\begin{align*} \mathbb{E}[m] \equiv \sum_{m=0}^{N} m\text{Bin}(m|N, \mu) &= N\mu \\ \text{var}[m] \equiv \sum_{m=0}^{N}(m - \mathbb{E}[m])^2 \text{Bin}(m|N, \mu) &= N\mu(1-\mu) \end{align*} \tag{2.12}$$

<br>

## The beta distribution
앞서 (2.8)에서 최대 가능도를 이용해 베르누이 분포의 파라미터 $\mu$에 대해 살펴봤습니다.
또한, 이항 분포에서는 $\mu$의 최대 가능도 추정값이 관측 데이터에서 $x=1$인 관측값의 비율로 계산된다는 것을 확인했습니다.
다만, 위에서 동전 던지기에서 모든 결과가 앞면이 나온다고 예측할 것이라고 언급한 것처럼 데이터의 수가 적을 때 심각한 과적합(over-fitting)이 발생하기 쉽습니다. 따라서, 이 문제를 해결하기 위해 베이지안 방식으로 접근해보도록 하겠습니다.

이 문제에 대해 베이지안 방식으로 접근하기 위해서는 파라미터 $\mu$에 대한
사전(prior) 분포 $p(\mu)$를 도입해야 합니다.
주목해야 할 점은 이제 $\mu$가 확률 변수(random variable)로 취급된다는 것입니다.
즉, 베이지안 관점에서는 파라미터를 확률 변수로 취급하여 일반적인 확률 분포로 다루게 됩니다.
여기서는 해석하기 쉽고 분석적인 측면에서도 유용한 형태의 사전 분포를 도입합니다.

동전 던지기 예제에서 가능도 함수가 $\mu^x(1-u)^{1-x}$의 거듭제곱으로 표현되고 있었습니다.
만약 $\mu$와
$(1-\mu)$의 거듭제곱에 비례하는 형태를 사전 분포로 선택한다면, 사전 확률과 가능도 함수의 곱에 비례하는 사후 분포 역시 사전 분포와 같은 함수 형태를 가지게 됩니다.
이러한 성질을 **켤레성**(conjugacy)이라고 합니다.

사전 확률과 사후 확률을 동일한 형태의 분포로 가져가기 위해 사전 분포로 **베타 분포**(beta distribution)을 사용합니다.
베타 분포는 다음의 형태를 가집니다.

$$\text{Beta}(\mu|a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} u^{a-1}(1-\mu)^{b-1} \tag{2.13}$$

여기서 사용된 감마(gamma) 함수는 식 (1.414)에 정의된 것과 같습니다.

$$\Gamma(x) \equiv \int_0^\infty u^{x-1}e^{-u}\mathrm{d}u \tag{1.414}$$

이를 계산하면 $\Gamma(x) = (x-1)!$를 얻을 수 있습니다.

식 (2.13)에서 계수들은 다음과 같이 베타 분포가 정규화(normalization)되도록 합니다.

$$\int_0^1 \text{Beta}(\mu|a, b) \mathrm{d}u = 1 \tag{2.14}$$

그리고, 베타 분포의 평균과 분산은 다음과 같습니다.

$$\begin{align*} \mathbb{E}[\mu] &= \frac{a}{a+b} \tag{2.15} \\ \text{var}[\mu] &= \frac{ab}{(a+b)^2(a+b+1)} \tag{2.16} \end{align*}$$

베타 분포에서 사용되는 파라미터 a와 b는 파라미터 $\mu$의 분포를 컨트롤하기 때문에 하이퍼파라미터(hyperparameters)라고 부르며, 아래 그림에서 다양한 하이퍼파라미터에 따른 베타 분포의 그래프를 확인할 수 있습니다.

<div align="center">
<tr>
<td><img src="{{ site.baseurl }}/assets/images/figures/Figure2.2a.png" height=250px></td>
<td><img src="{{ site.baseurl }}/assets/images/figures/Figure2.2b.png" height=250px></td>
</tr>
<tr>
<td><img src="{{ site.baseurl }}/assets/images/figures/Figure2.2a.png" height=250px></td>
<td><img src="{{ site.baseurl }}/assets/images/figures/Figure2.2b.png" height=250px></td>
</tr>
<div align="center">Figure 2.2</div>
</div>

<br>
<br>

동전 던지기 예제의 사후 분포는 식 (2.13)의 베타 사전 분포와 식 (2.9)의 이항 분포의 가능도 함수를 곱한 후 정규화를 수행하여 구할 수 있습니다. $\mu$와 관련되어 있는 인자들만 남기면 사후 분포가 다음의 형태를 가지게 됩니다.

$$p(\mu|m,l,a,b) \propto \mu^{m+a-1}(1-\mu)^{l+b-1} \tag{2.17}$$

여기서 $l = N-m$이며, 동전 던지기에서 '뒷면'의 개수에 해당합니다. 사후 분포의 식 (2.17)을 살펴보면 사전 분포와 같은 형태의 함수라는 것을 확인할 수 있습니다. 즉, 사전 분포로 베타 분포를 사용하여 사후 분포도 베타 분포가 되었고, 실제로 사후 분포는 단순히 또 다른 베타 분포일 뿐입니다. 이렇게 얻은 새로운 베타 분포의 정규화 계수는 식 (2.13)에 의해서 다음과 같이 얻을 수 있습니다.

$$p(\mu|m, l, a, b) = \frac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)}\mu^{m+a-1}(1-\mu)^{l+b-1} \tag{2.18}$$

이를 사전 분포와 비교했을 때 사후 분포에서는 a의 값이 m만큼, b의 값이 l만큼 증가한 것을 확인할 수 있습니다.
이로부터 사전 분포의 하이퍼파라미터 a와 b를 각각 $x=1$, $x=0$인 경우에 대한 **유효 관찰수**(effective number of observations)로 해석할 수 있습니다. a와 b는 반드시 정수가 아니어도 되며, 만약 추가로 관측 데이터를 얻게 된다면 지금의 사후 분포가 새로운 사전 분포가 될 수도 있습니다. 

이를 살펴보기 위해서 한 번에 하나의 관측값을 받고 받은 관측값의 가능도 함수를 곱하고 정규화를 수행하여 사후 분포를 업데이트한다고 상상해봅시다. 매 단계에서 사후 분포는 $x=1$, $x=0$에 해당하는 전체 관측값의 수가 새로운 a와 b로 주어지는 베타 분포가 됩니다. 만약 $x=1$인 새로운 관측값이 하나 주어졌을 때는 a의 값을 1 증가시키고, $x=0$인 관측값이 하나 주어졌을 때는 b의 값을 1 증가시키면 됩니다. 이러한 과정의 한 단계를 그림으로 표현하면 다음과 같습니다.
<div align="center">
<tr>
<td><img src="{{ site.baseurl }}/assets/images/figures/Figure2.3a.png" height=200px></td>
<td><img src="{{ site.baseurl }}/assets/images/figures/Figure2.3b.png" height=200px></td>
<td><img src="{{ site.baseurl }}/assets/images/figures/Figure2.3c.png" height=200px></td>
</tr>
<div align="center">Figure 2.3</div>
</div>

<br>

위 그림에서 사전 분포는 $a=2, b=2$인 베타 분포로 주어졌고, 가운데 그림은 $x=1$인 하나의 관측값에 대한 가능도 함수에 하당합니다. 이를 바탕으로 새로운 사후 분포는 $a=3, b=2$인 베타 분포가 됩니다.

<br>

베이지안 관점을 이해하면 학습에서 이러한 **순차적**(sequential)인 접근을 자연스럽게 이해하게 됩니다. 순차적인 방법론은 관측값을 한 번에 하나씩, 혹은 한 번에 적은 수(small batches)를 사용하고 다음 관측값을 사용하기 전에 버립니다. 이는 사전 분포나 가능도 함수의 선택은 독립적이며, 데이터가 **i.i.d**(independent and identically distribution)이라는 것에만 의존적입니다. 실시간 학습과 같이 데이터 스트림이 지속적으로 입력되고, 전체 데이터를 다 학습하기 전에 예측을 시행해야하는 경우에 이러한 순차적인 방법론을 적용할 수 있습니다. 또한, 전체 데이터 집합이 메모리에 로드되거나 저장될 필요가 없기 때문에 큰 데이터 집합을 처리하는 데도 적합합니다. 

만약 우리의 목표가 다음번 시도의 결과를 잘 예측하는 것이라면 주어진 관측 데이터 집합 $\mathcal{D}$가 주어졌을 때 $x$의 예측 분포(predictive distribution)을 찾아야 합니다. 확률의 합/곱의 법칙에 의해 이는 다음과 같습니다.

$$p(x=1|\mathcal{D}) = \int_0^1 p(x=1|\mu)p(\mu|\mathcal{D})\mathrm{d}u = \int_0^1 \mu p(\mu|\mathcal{D})\mathrm{d}u = \mathbb{E}[\mu|\mathcal{D}] \tag{2.19}$$

베타 분포의 평균에 해당하는 식 (2.15)와 사후 분포 $p(\mu\|\mathcal{D})$에 대한 결과인 식 (2.18)을 이용하면 다음과 같이 식 (2.19)를 구할 수 있습니다.

$$p(x=1|\mathcal{D}) = \frac{m+a}{m+a+l+b} \tag{2.20}$$

위 식은 단순히 전체 관측값(실제 관측값 + 허구인 사전 관측값) 중에서 $x=1$인 관측값의 비율로 해석될 수 있습니다. 만약 데이터 집합이 무한히 커서 $m, l \rightarrow \infty$라면 식 (2.20)은 식 (2.8)의 최대 가능도의 결과와 같아집니다. 즉, 사전 분포의 관측값 수인 $a, b$의 영향이 사라집니다. 만약 데이터의 수가 적다면 사전 분포는 중요한 역할을 수행하고, 잘못된 사전 분포를 사용하게 되면 잘못된 결과를 얻을 수도 있습니다. 따라서 사전 분포를 선택하는 것도 중요합니다.

만약 데이터의 크기가 제한되어 있다면 집합에서 $\mu$의 사후 평균값은 사전 평균값과 식 (2.7)에서 주어진 사건의 상대적인 빈도수로 계산되는 최대 가능도 추정치(MLE) 사이에 존재하게 됩니다. 즉, 빈도적 관점에서 얻은 MLE 값과 베이지안 관점에서 얻은 사전 분포의 평균값 사이에 존재한다는 것을 의미합니다.

<br>

Figure 2.2에서 관측값의 수가 증가할수록 사후 분포가 더 뾰족해지는 것을 볼 수 있습니다. 이는 베타 분포의 분산인 식 (2.16)의 결과에서도 확인할 수 있는데, $a \rightarrow \infty$ 또는 $b \rightarrow \infty$가 되면 분산이 0에 수렴하기 때문입니다.

<br>

여기서 의문점은 베이지안 관점에서 관측된 데이터가 많아질수록 사후 분포의 불확실성 계속 감소하는가에 대한 것입니다. 이를 확인하기 위해서 빈도적 관점에서 살펴볼텐데, 일반적으로 관측 데이터 수가 많아질수록 사후 분포의 불확실성이 감소한다는 것을 알 수 있습니다.

관측된 데이터 집합 $\mathcal{D}$에 대해서
파라미터 $\boldsymbol{\theta}$를 추정하는 일반적인 베이지안 추론 문제를 살펴보겠습니다.
이 문제는 결합 분포(joint distribution) $p(\boldsymbol{\theta}, \mathcal{D})$로 표현 가능하며,
파라미터 $\boldsymbol{\theta}$에 대한 기댓값은 다음과 같습니다.

$$\begin{align*} \mathbb{E}_{\boldsymbol{\theta}}[\boldsymbol{\theta}] &= \mathbb{E}_\mathcal{D}[\mathbb{E}_{\boldsymbol{\theta}}[\boldsymbol{\theta}|\mathcal{D}]] \tag{2.21} \\ \mathbb{E}_{\boldsymbol{\theta}}[\boldsymbol{\theta}] &\equiv \int p(\boldsymbol{\theta})\boldsymbol{\theta}\mathrm{d}\boldsymbol{\theta} \tag{2.22} \\ \mathbb{E}_\mathcal{D}[\mathbb{E}_{\boldsymbol{\theta}}[\boldsymbol{\theta}|\mathcal{D}]] &\equiv \int \left \lbrace  \int \boldsymbol{\theta} p(\boldsymbol{\theta}|\mathcal{D}) \mathrm{d}\boldsymbol{\theta} \right \rbrace p(\mathcal{D}) \mathrm{d}\mathcal{D} \tag{2.23} \end{align*}$$

식 (2.21)로부터 데이터를 생성하는 분포에 대해 평균을 낸 $\theta$의 사후 평균값은
$\theta$의 사전 평균과 같습니다.

이와 유사하게 아래의 식도 증명할 수 있습니다.

$$\text{var}_{\boldsymbol{\theta}}[\boldsymbol{\theta}] = \mathbb{E}_\mathcal{D}[\text{var}_{\boldsymbol{\theta}}[\boldsymbol{\theta}|\mathcal{D}]] + \text{var}_\mathcal{D}[\mathbb{E}_{\boldsymbol{\theta}}[\boldsymbol{\theta}|\mathcal{D}]] \tag{2.24}$$

식 (2.24)의 왼쪽 변은 $\boldsymbol{\theta}$의 사전 분산에 해당하고,
오른쪽 변의 첫 번째 항은 $\boldsymbol{\theta}$의 사후 분산의 평균,
두 번째 항은 $\boldsymbol{\theta}$의 사후 평균의 분산에 해당합니다.
식 (2.24)은 양의 값(분산)을 가지기 때문에 평균적으로 $\boldsymbol{\theta}$의 사후 분산은 사전 분산보다 작다는 것을 알 수 있습니다.

하지만, 특정 관측 데이터 집합에서는 사후 분산이 사전 분산보다 클수도 있습니다.